{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8466680",
   "metadata": {},
   "source": [
    "# Body Type Classifier for Dress Recommendation Demo\n",
    "\n",
    "This notebook creates a tiny body type classifier that can run in the browser via TensorFlow.js or simple coefficient-based classification. The model will classify users into 5 body types based on shoulder/waist/hip ratios extracted from pose detection.\n",
    "\n",
    "## Body Types:\n",
    "- **Hourglass**: Balanced shoulders/hips with defined waist\n",
    "- **Pear**: Larger hips relative to shoulders  \n",
    "- **Apple**: Larger midsection, less defined waist\n",
    "- **Rectangle**: Similar measurements throughout\n",
    "- **Inverted Triangle**: Broader shoulders than hips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b63d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# TensorFlow for alternative model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Dependencies loaded successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d55b693",
   "metadata": {},
   "source": [
    "## Generate Synthetic Body Type Dataset\n",
    "\n",
    "We'll create synthetic data based on typical body proportions:\n",
    "- **r1 = waist/shoulder ratio**\n",
    "- **r2 = hip/shoulder ratio**\n",
    "\n",
    "Each body type has characteristic ranges for these ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a1d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n_samples_per_class=200):\n",
    "    \"\"\"Generate synthetic body type data based on typical proportions\"\"\"\n",
    "    \n",
    "    # Define characteristic ranges for each body type\n",
    "    body_type_params = {\n",
    "        'hourglass': {\n",
    "            'r1_mean': 0.72, 'r1_std': 0.06,  # defined waist\n",
    "            'r2_mean': 0.95, 'r2_std': 0.08   # hips similar to shoulders\n",
    "        },\n",
    "        'pear': {\n",
    "            'r1_mean': 0.78, 'r1_std': 0.05,  # less defined waist\n",
    "            'r2_mean': 1.15, 'r2_std': 0.10   # larger hips\n",
    "        },\n",
    "        'apple': {\n",
    "            'r1_mean': 0.88, 'r1_std': 0.07,  # less defined waist\n",
    "            'r2_mean': 0.92, 'r2_std': 0.06   # smaller hips\n",
    "        },\n",
    "        'rectangle': {\n",
    "            'r1_mean': 0.85, 'r1_std': 0.04,  # straight through\n",
    "            'r2_mean': 0.90, 'r2_std': 0.05   # similar measurements\n",
    "        },\n",
    "        'inverted_triangle': {\n",
    "            'r1_mean': 0.82, 'r1_std': 0.05,  # broader shoulders\n",
    "            'r2_mean': 0.78, 'r2_std': 0.08   # narrower hips\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for body_type, params in body_type_params.items():\n",
    "        # Generate r1 (waist/shoulder) ratios\n",
    "        r1_samples = np.random.normal(\n",
    "            params['r1_mean'], params['r1_std'], n_samples_per_class\n",
    "        )\n",
    "        \n",
    "        # Generate r2 (hip/shoulder) ratios\n",
    "        r2_samples = np.random.normal(\n",
    "            params['r2_mean'], params['r2_std'], n_samples_per_class\n",
    "        )\n",
    "        \n",
    "        # Clip to reasonable bounds\n",
    "        r1_samples = np.clip(r1_samples, 0.6, 1.0)\n",
    "        r2_samples = np.clip(r2_samples, 0.7, 1.3)\n",
    "        \n",
    "        # Add samples to dataset\n",
    "        for r1, r2 in zip(r1_samples, r2_samples):\n",
    "            data.append([r1, r2])\n",
    "            labels.append(body_type)\n",
    "    \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Generate the dataset\n",
    "X, y = generate_synthetic_data(n_samples_per_class=200)\n",
    "print(f\"Generated {len(X)} samples with {len(np.unique(y))} body types\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Body types: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d431d4a",
   "metadata": {},
   "source": [
    "## Visualize Body Type Clusters\n",
    "\n",
    "Let's visualize the synthetic data to see how well the different body types are separated in the ratio space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for easier plotting\n",
    "df = pd.DataFrame(X, columns=['r1_waist_shoulder', 'r2_hip_shoulder'])\n",
    "df['body_type'] = y\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Color map for body types\n",
    "colors = {'hourglass': 'red', 'pear': 'green', 'apple': 'orange', \n",
    "          'rectangle': 'blue', 'inverted_triangle': 'purple'}\n",
    "\n",
    "for body_type in df['body_type'].unique():\n",
    "    mask = df['body_type'] == body_type\n",
    "    plt.scatter(df[mask]['r1_waist_shoulder'], df[mask]['r2_hip_shoulder'], \n",
    "                c=colors[body_type], label=body_type, alpha=0.6, s=30)\n",
    "\n",
    "plt.xlabel('r1: Waist/Shoulder Ratio', fontsize=12)\n",
    "plt.ylabel('r2: Hip/Shoulder Ratio', fontsize=12)\n",
    "plt.title('Body Type Classification - Synthetic Dataset', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Dataset Summary:\")\n",
    "print(df.groupby('body_type').agg({\n",
    "    'r1_waist_shoulder': ['mean', 'std'],\n",
    "    'r2_hip_shoulder': ['mean', 'std']\n",
    "}).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1eb345",
   "metadata": {},
   "source": [
    "## Train Logistic Regression Classifier\n",
    "\n",
    "We'll train a simple logistic regression model that can be easily exported as JSON coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63998a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Train logistic regression model\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nLogistic Regression Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred, labels=lr_model.classes_)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=lr_model.classes_, yticklabels=lr_model.classes_)\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dc9bd0",
   "metadata": {},
   "source": [
    "## Export Coefficients to JSON\n",
    "\n",
    "Export the trained logistic regression weights and biases to a JSON file that the React app can load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f49cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the coefficients dictionary\n",
    "coefficients_data = {\n",
    "    \"model_type\": \"logistic_regression\",\n",
    "    \"labels\": lr_model.classes_.tolist(),\n",
    "    \"coefficients\": lr_model.coef_.tolist(),\n",
    "    \"intercept\": lr_model.intercept_.tolist(),\n",
    "    \"feature_names\": [\"r1_waist_shoulder\", \"r2_hip_shoulder\"],\n",
    "    \"accuracy\": float(accuracy),\n",
    "    \"created_timestamp\": pd.Timestamp.now().isoformat()\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(\"../public/model\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save coefficients to JSON\n",
    "coefficients_path = output_dir / \"coefficients.json\"\n",
    "with open(coefficients_path, 'w') as f:\n",
    "    json.dump(coefficients_data, f, indent=2)\n",
    "\n",
    "print(f\"Coefficients exported to: {coefficients_path}\")\n",
    "print(f\"File size: {coefficients_path.stat().st_size} bytes\")\n",
    "\n",
    "# Display the structure\n",
    "print(\"\\nExported coefficients structure:\")\n",
    "for key, value in coefficients_data.items():\n",
    "    if isinstance(value, list) and len(value) > 3:\n",
    "        print(f\"  {key}: [array with {len(value)} elements]\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7855d",
   "metadata": {},
   "source": [
    "## Train Alternative TensorFlow Model\n",
    "\n",
    "Create a small neural network as an alternative to the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5489f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for TensorFlow\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "n_classes = len(np.unique(y_encoded))\n",
    "\n",
    "# Split encoded data\n",
    "X_train_tf, X_test_tf, y_train_tf, y_test_tf = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Convert to TensorFlow format\n",
    "y_train_tf_cat = tf.keras.utils.to_categorical(y_train_tf, n_classes)\n",
    "y_test_tf_cat = tf.keras.utils.to_categorical(y_test_tf, n_classes)\n",
    "\n",
    "# Create a simple neural network\n",
    "tf_model = keras.Sequential([\n",
    "    layers.Input(shape=(2,)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "tf_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"TensorFlow Model Summary:\")\n",
    "tf_model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = tf_model.fit(\n",
    "    X_train_tf, y_train_tf_cat,\n",
    "    validation_data=(X_test_tf, y_test_tf_cat),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "tf_loss, tf_accuracy = tf_model.evaluate(X_test_tf, y_test_tf_cat, verbose=0)\n",
    "print(f\"\\nTensorFlow Model Accuracy: {tf_accuracy:.3f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5c1512",
   "metadata": {},
   "source": [
    "## Convert TensorFlow Model to TensorFlow.js\n",
    "\n",
    "Convert the trained model to TensorFlow.js format for use in the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01adccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflowjs as tfjs\n",
    "    \n",
    "    # Save the model in TensorFlow.js format\n",
    "    tfjs_path = output_dir / \"tfjs_model\"\n",
    "    tfjs_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    tfjs.converters.save_keras_model(tf_model, str(tfjs_path))\n",
    "    print(f\"TensorFlow.js model saved to: {tfjs_path}\")\n",
    "    \n",
    "    # Create metadata file for the TensorFlow.js model\n",
    "    tfjs_metadata = {\n",
    "        \"model_type\": \"tensorflow\",\n",
    "        \"labels\": label_encoder.classes_.tolist(),\n",
    "        \"input_shape\": [2],\n",
    "        \"output_shape\": [n_classes],\n",
    "        \"feature_names\": [\"r1_waist_shoulder\", \"r2_hip_shoulder\"],\n",
    "        \"accuracy\": float(tf_accuracy),\n",
    "        \"created_timestamp\": pd.Timestamp.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    metadata_path = output_dir / \"tfjs_metadata.json\"\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(tfjs_metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"Metadata saved to: {metadata_path}\")\n",
    "    \n",
    "    # List generated files\n",
    "    print(\"\\nGenerated TensorFlow.js files:\")\n",
    "    for file in tfjs_path.iterdir():\n",
    "        print(f\"  {file.name}: {file.stat().st_size} bytes\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"TensorFlow.js converter not available. Installing...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'tensorflowjs'])\n",
    "        import tensorflowjs as tfjs\n",
    "        \n",
    "        # Retry the conversion\n",
    "        tfjs_path = output_dir / \"tfjs_model\"\n",
    "        tfjs_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        tfjs.converters.save_keras_model(tf_model, str(tfjs_path))\n",
    "        print(f\"TensorFlow.js model saved to: {tfjs_path}\")\n",
    "        \n",
    "        # Create metadata\n",
    "        tfjs_metadata = {\n",
    "            \"model_type\": \"tensorflow\",\n",
    "            \"labels\": label_encoder.classes_.tolist(),\n",
    "            \"input_shape\": [2],\n",
    "            \"output_shape\": [n_classes],\n",
    "            \"feature_names\": [\"r1_waist_shoulder\", \"r2_hip_shoulder\"],\n",
    "            \"accuracy\": float(tf_accuracy),\n",
    "            \"created_timestamp\": pd.Timestamp.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        metadata_path = output_dir / \"tfjs_metadata.json\"\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(tfjs_metadata, f, indent=2)\n",
    "        \n",
    "        print(f\"Metadata saved to: {metadata_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not install/use TensorFlow.js converter: {e}\")\n",
    "        print(\"Skipping TensorFlow.js model export. The coefficients.json model will still work.\")\n",
    "        \n",
    "        # Create a placeholder metadata file\n",
    "        tfjs_metadata = {\n",
    "            \"model_type\": \"tensorflow_unavailable\",\n",
    "            \"labels\": label_encoder.classes_.tolist(),\n",
    "            \"note\": \"TensorFlow.js conversion failed, using coefficients.json instead\"\n",
    "        }\n",
    "        \n",
    "        metadata_path = output_dir / \"tfjs_metadata.json\"\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(tfjs_metadata, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc7a44",
   "metadata": {},
   "source": [
    "## Validation and Sanity Checks\n",
    "\n",
    "Test both exported models with sample predictions to ensure they work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109a7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test samples representing different body types\n",
    "test_samples = np.array([\n",
    "    [0.72, 0.95],  # hourglass\n",
    "    [0.78, 1.15],  # pear\n",
    "    [0.88, 0.92],  # apple\n",
    "    [0.85, 0.90],  # rectangle\n",
    "    [0.82, 0.78]   # inverted_triangle\n",
    "])\n",
    "\n",
    "expected_types = ['hourglass', 'pear', 'apple', 'rectangle', 'inverted_triangle']\n",
    "\n",
    "print(\"=== Sanity Check Results ===\")\n",
    "print(f\"{'Sample':<12} {'r1':<6} {'r2':<6} {'LogReg':<17} {'TF':<17} {'Expected':<17}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, (sample, expected) in enumerate(zip(test_samples, expected_types)):\n",
    "    # Logistic regression prediction\n",
    "    lr_pred = lr_model.predict([sample])[0]\n",
    "    lr_prob = lr_model.predict_proba([sample])[0].max()\n",
    "    \n",
    "    # TensorFlow prediction\n",
    "    tf_pred_probs = tf_model.predict([sample], verbose=0)[0]\n",
    "    tf_pred_idx = np.argmax(tf_pred_probs)\n",
    "    tf_pred = label_encoder.classes_[tf_pred_idx]\n",
    "    tf_prob = tf_pred_probs[tf_pred_idx]\n",
    "    \n",
    "    print(f\"Sample {i+1:<5} {sample[0]:<6.2f} {sample[1]:<6.2f} \"\n",
    "          f\"{lr_pred:<12}({lr_prob:.2f}) {tf_pred:<12}({tf_prob:.2f}) {expected:<17}\")\n",
    "\n",
    "print(\"\\n=== Model Comparison ===\")\n",
    "print(f\"Logistic Regression Accuracy: {accuracy:.3f}\")\n",
    "print(f\"TensorFlow Model Accuracy:    {tf_accuracy:.3f}\")\n",
    "\n",
    "# Test loading the exported JSON coefficients\n",
    "print(\"\\n=== JSON Coefficients Test ===\")\n",
    "with open(coefficients_path, 'r') as f:\n",
    "    loaded_coefficients = json.load(f)\n",
    "\n",
    "print(\"Successfully loaded coefficients.json\")\n",
    "print(f\"Model type: {loaded_coefficients['model_type']}\")\n",
    "print(f\"Labels: {loaded_coefficients['labels']}\")\n",
    "print(f\"Accuracy: {loaded_coefficients['accuracy']:.3f}\")\n",
    "\n",
    "# Manual prediction using loaded coefficients (simplified)\n",
    "def predict_from_coefficients(sample, coefficients):\n",
    "    \"\"\"Simple manual prediction using loaded coefficients\"\"\"\n",
    "    import math\n",
    "    \n",
    "    coef = np.array(coefficients['coefficients'])\n",
    "    intercept = np.array(coefficients['intercept'])\n",
    "    labels = coefficients['labels']\n",
    "    \n",
    "    # Calculate scores for each class\n",
    "    scores = np.dot(coef, sample) + intercept\n",
    "    \n",
    "    # Softmax\n",
    "    exp_scores = np.exp(scores - np.max(scores))\n",
    "    probabilities = exp_scores / np.sum(exp_scores)\n",
    "    \n",
    "    predicted_idx = np.argmax(probabilities)\n",
    "    return labels[predicted_idx], probabilities[predicted_idx]\n",
    "\n",
    "# Test manual prediction\n",
    "sample = test_samples[0]  # hourglass example\n",
    "pred_label, pred_prob = predict_from_coefficients(sample, loaded_coefficients)\n",
    "print(f\"Manual prediction for {sample}: {pred_label} (confidence: {pred_prob:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6693a6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We have successfully created and exported two models for body type classification:\n",
    "\n",
    "1. **Logistic Regression Model** → `coefficients.json` (lightweight, easy to implement)\n",
    "2. **TensorFlow Model** → `tfjs_model/` (more complex but potentially more accurate)\n",
    "\n",
    "Both models can classify users into 5 body types based on waist/shoulder and hip/shoulder ratios extracted from pose detection.\n",
    "\n",
    "### Next Steps\n",
    "- Use these models in the React app\n",
    "- Test with real pose detection data\n",
    "- Fine-tune thresholds based on real-world performance\n",
    "\n",
    "### Files Generated\n",
    "- `../public/model/coefficients.json` - Logistic regression weights\n",
    "- `../public/model/tfjs_model/` - TensorFlow.js model files\n",
    "- `../public/model/tfjs_metadata.json` - Model metadata"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
